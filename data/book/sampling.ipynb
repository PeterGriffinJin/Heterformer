{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dfa9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575d66f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we select shelves, author, publisher, language_code, format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54395a0",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f0263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read book data\n",
    "train_data = []\n",
    "\n",
    "with open('raw/train.tsv') as f:\n",
    "    readin = f.readlines()\n",
    "    for line in tqdm(readin):\n",
    "        tmp = json.loads(line)\n",
    "        train_data.append(tmp)\n",
    "        \n",
    "val_data = []\n",
    "\n",
    "with open('raw/val.tsv') as f:\n",
    "    readin = f.readlines()\n",
    "    for line in tqdm(readin):\n",
    "        tmp = json.loads(line)\n",
    "        val_data.append(tmp)\n",
    "        \n",
    "test_data = []\n",
    "\n",
    "with open('raw/test.tsv') as f:\n",
    "    readin = f.readlines()\n",
    "    for line in tqdm(readin):\n",
    "        tmp = json.loads(line)\n",
    "        test_data.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215ddc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read filtered shelves dict (1000~100000)\n",
    "shelves_degree_dict = pickle.load(open('raw/shelves_degree_dict_1000_100000.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc37d19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b56b0575",
   "metadata": {},
   "source": [
    "## process training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca20dd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# collect shelves, author, publisher, language_code, format base on train set\n",
    "\n",
    "bookid_set = set()\n",
    "publisher_set = set()\n",
    "language_code_set = set()\n",
    "format_set = set()\n",
    "shelves_set = set()\n",
    "author_set = set()\n",
    "\n",
    "for b in tqdm(train_data):\n",
    "    bookid_set.add(b['book_id'])\n",
    "    \n",
    "    if b['publisher'] != '':\n",
    "        publisher_set.add(b['publisher'])\n",
    "        \n",
    "    if b['language_code'] != '':\n",
    "        language_code_set.add(b['language_code'])\n",
    "        \n",
    "    if b['format'] != '':\n",
    "        format_set.add(b['format'])\n",
    "        \n",
    "    for ss in b['popular_shelves']:\n",
    "        if ss['name'] in shelves_degree_dict:\n",
    "            shelves_set.add(ss['name'])\n",
    "    \n",
    "    for aa in b['authors']:\n",
    "        author_set.add(aa['author_id'])\n",
    "\n",
    "print(f'Book:{len(bookid_set)}, Publisher:{len(publisher_set)}, Language_code:{len(language_code_set)}, Format:{len(format_set)}, shelves:{len(shelves_set)}, author:{len(author_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06b24c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# filter similar_paper_list for each paper inside train/val/test\n",
    "\n",
    "for i in tqdm(range(len(train_data))):\n",
    "    train_data[i]['similar_books'] = list(set(train_data[i]['similar_books']) & bookid_set)\n",
    "    \n",
    "for i in tqdm(range(len(val_data))):\n",
    "    val_data[i]['similar_books'] = list(set(val_data[i]['similar_books']) & bookid_set)\n",
    "\n",
    "for i in tqdm(range(len(test_data))):\n",
    "    test_data[i]['similar_books'] = list(set(test_data[i]['similar_books']) & bookid_set)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467e4311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper-paper edge statistics\n",
    "cnt = 0\n",
    "\n",
    "for d in tqdm(train_data):\n",
    "    if 'similar_books' not in d:\n",
    "        continue\n",
    "    cnt += len(d['similar_books'])\n",
    "\n",
    "for d in tqdm(val_data):\n",
    "    if 'similar_books' not in d:\n",
    "        continue\n",
    "    cnt += len(d['similar_books'])\n",
    "    \n",
    "for d in tqdm(test_data):\n",
    "    if 'similar_books' not in d:\n",
    "        continue\n",
    "    cnt += len(d['similar_books'])\n",
    "    \n",
    "print(f'paper-paper edge num:{cnt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b583dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter shelves_list for each paper inside train/val/test\n",
    "\n",
    "for i in tqdm(range(len(train_data))):\n",
    "    new_list = []\n",
    "    for ss in train_data[i]['popular_shelves']:\n",
    "        if ss['name'] in shelves_degree_dict:\n",
    "            new_list.append(ss)\n",
    "    train_data[i]['popular_shelves'] = new_list\n",
    "    \n",
    "for i in tqdm(range(len(val_data))):\n",
    "    new_list = []\n",
    "    for ss in val_data[i]['popular_shelves']:\n",
    "        if ss['name'] in shelves_degree_dict:\n",
    "            new_list.append(ss)\n",
    "    val_data[i]['popular_shelves'] = new_list\n",
    "    \n",
    "for i in tqdm(range(len(test_data))):\n",
    "    new_list = []\n",
    "    for ss in test_data[i]['popular_shelves']:\n",
    "        if ss['name'] in shelves_degree_dict:\n",
    "            new_list.append(ss)\n",
    "    test_data[i]['popular_shelves'] = new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff4b3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct id2idx_dict for shelves, author, publisher, language_code, format\n",
    "\n",
    "shelves_id2idx_dict = {}\n",
    "author_id2idx_dict = {}\n",
    "publisher_id2idx_dict = {}\n",
    "language_code_id2idx_dict = {}\n",
    "format_id2idx_dict = {}\n",
    "\n",
    "for ss in tqdm(shelves_set):\n",
    "    shelves_id2idx_dict[ss] = len(shelves_id2idx_dict)\n",
    "\n",
    "for aa in tqdm(author_set):\n",
    "    author_id2idx_dict[aa] = len(author_id2idx_dict)\n",
    "\n",
    "for pp in tqdm(publisher_set):\n",
    "    publisher_id2idx_dict[pp] = len(publisher_id2idx_dict)\n",
    "    \n",
    "for ll in tqdm(language_code_set):\n",
    "    language_code_id2idx_dict[ll] = len(language_code_id2idx_dict)\n",
    "    \n",
    "for ff in tqdm(format_set):\n",
    "    format_id2idx_dict[ff] = len(format_id2idx_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eda4143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg statistics for similar book & shelves\n",
    "\n",
    "similar_book_sum = 0\n",
    "shelves_sum = 0\n",
    "\n",
    "for b in tqdm(train_data):\n",
    "    similar_book_sum += len(b['similar_books'])\n",
    "    shelves_sum += len(b['popular_shelves'])\n",
    "    \n",
    "print(f'Average similar book:{similar_book_sum / len(train_data)}, Average shelves:{shelves_sum / len(train_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b10c62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c0fcc5a",
   "metadata": {},
   "source": [
    "## File Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c156190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence: book, shelves, author, publisher, language_code, format\n",
    "book_neighbour = 5\n",
    "shelves_neighbour = 5\n",
    "author_neighbour = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce1d298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate book_info_dict for books in trainset\n",
    "\n",
    "train_book_dict = {} # key: book_id, value: book_dict\n",
    "\n",
    "for b in tqdm(train_data):\n",
    "    assert b['book_id'] not in train_book_dict\n",
    "    train_book_dict[b['book_id']] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d1e575",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate train pairs and delete them in each other's similar_paper_list\n",
    "\n",
    "train_pairs = []\n",
    "simple_direction_cnt = 0\n",
    "empty_cnt = 0\n",
    "\n",
    "for b in tqdm(train_data):\n",
    "    if len(b['similar_books']) == 0:\n",
    "        empty_cnt += 1\n",
    "    else:\n",
    "        # sample key for tmp query\n",
    "        sample_key = random.choice(b['similar_books'])\n",
    "\n",
    "        # delete book_id in each other's similar_books list\n",
    "        train_book_dict[b['book_id']]['similar_books'].pop(train_book_dict[b['book_id']]['similar_books'].index(sample_key))\n",
    "        if b['book_id'] in set(train_book_dict[sample_key]['similar_books']):\n",
    "            train_book_dict[sample_key]['similar_books'].pop(train_book_dict[sample_key]['similar_books'].index(b['book_id']))\n",
    "        else:\n",
    "            simple_direction_cnt += 1\n",
    "\n",
    "        # add sampled pairs into train_pairs\n",
    "        train_pairs.append((b['book_id'], sample_key))\n",
    "\n",
    "print(f'Num of train pairs:{len(train_pairs)}, simple_direction_cnt:{simple_direction_cnt}, empty_cnt:{empty_cnt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774a4b1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sampling function for each book\n",
    "# book_text, book_neighbour * 5, shelves * 5, author * 2, publisher, language_code, format\n",
    "\n",
    "# book_neighbour = 5\n",
    "# shelves_neighbour = 5\n",
    "# author_neighbour = 2\n",
    "\n",
    "def remove_next_line(text):\n",
    "    t = ' '.join(text.strip().split('\\n'))\n",
    "    \n",
    "    return ' '.join(t.split('\\t'))\n",
    "\n",
    "def mysampling(book_info_dict):\n",
    "    \n",
    "    result_list = []\n",
    "    \n",
    "    # center book text\n",
    "    book_text = remove_next_line(book_info_dict['title']+book_info_dict['description'])\n",
    "    result_list.append(book_text)\n",
    "\n",
    "    # sample book neighbour\n",
    "    if len(book_info_dict['similar_books']) >= book_neighbour:\n",
    "        random.shuffle(book_info_dict['similar_books'])\n",
    "        sampled_book_neighbours = [remove_next_line(train_book_dict[bid]['title']+train_book_dict[bid]['description']) for bid in book_info_dict['similar_books'][:book_neighbour]]\n",
    "    else:\n",
    "        sampled_book_neighbours = [remove_next_line(train_book_dict[bid]['title']+train_book_dict[bid]['description']) for bid in book_info_dict['similar_books']] + [''] * (book_neighbour - len(book_info_dict['similar_books']))\n",
    "    result_list += sampled_book_neighbours\n",
    "    \n",
    "    # sample shelves neighbour\n",
    "    sampled_shelves_neighbours = []\n",
    "    tmp_shelves_neighbours = sorted(book_info_dict['popular_shelves'], key=lambda x:-int(x['count']))\n",
    "    if len(tmp_shelves_neighbours) >= shelves_neighbour:\n",
    "        sampled_shelves_neighbours = [str(shelves_id2idx_dict[ss['name']]) for ss in tmp_shelves_neighbours[:book_neighbour]]\n",
    "    else:\n",
    "        sampled_shelves_neighbours = [str(shelves_id2idx_dict[ss['name']]) for ss in tmp_shelves_neighbours] + ['-1'] * (shelves_neighbour - len(tmp_shelves_neighbours))\n",
    "    result_list += sampled_shelves_neighbours\n",
    "    \n",
    "    # sample author neighbour\n",
    "    sampled_author_neighbours = []\n",
    "    book_authors = [aa['author_id'] for aa in book_info_dict['authors']]\n",
    "    book_authors = list(set(book_authors) & author_set)\n",
    "    random.shuffle(book_authors)\n",
    "    if len(book_authors) >= author_neighbour:\n",
    "        sampled_author_neighbours = [str(author_id2idx_dict[aa]) for aa in book_authors[:author_neighbour]]\n",
    "    else:\n",
    "        sampled_author_neighbours = [str(author_id2idx_dict[aa]) for aa in book_authors] + ['-1'] * (author_neighbour - len(book_authors))\n",
    "    result_list += sampled_author_neighbours\n",
    "    \n",
    "    # publisher\n",
    "    if book_info_dict['publisher'] != '' and book_info_dict['publisher'] in publisher_set:\n",
    "        publisher = str(publisher_id2idx_dict[book_info_dict['publisher']])\n",
    "    else:\n",
    "        publisher = '-1'\n",
    "    result_list.append(publisher)\n",
    "    \n",
    "    # language_code\n",
    "    if book_info_dict['language_code'] != '' and book_info_dict['language_code'] in language_code_set:\n",
    "        language_code = str(language_code_id2idx_dict[book_info_dict['language_code']])\n",
    "    else:\n",
    "        language_code = '-1'\n",
    "    result_list.append(language_code)\n",
    "    \n",
    "    # format\n",
    "    if book_info_dict['format'] != '' and book_info_dict['format'] in format_set:\n",
    "        formats = str(format_id2idx_dict[book_info_dict['format']])\n",
    "    else:\n",
    "        formats = '-1'\n",
    "    result_list.append(formats)\n",
    "    \n",
    "    return '\\t'.join(result_list)\n",
    "\n",
    "# exp\n",
    "#a = deepcopy(train_data[3])\n",
    "#r = mysampling(a)\n",
    "#print(train_data[3])\n",
    "#print('**********************')\n",
    "#print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfd0273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train file generation\n",
    "\n",
    "query_cnt = 0\n",
    "key_cnt = 0\n",
    "\n",
    "with open('data/book/train.tsv', 'w') as fout:\n",
    "    for train_pair in tqdm(train_pairs):\n",
    "        query_info_dict = deepcopy(train_book_dict[train_pair[0]])\n",
    "        key_info_dict = deepcopy(train_book_dict[train_pair[1]])\n",
    "        query_info = mysampling(query_info_dict)\n",
    "        key_info = mysampling(key_info_dict)\n",
    "        \n",
    "        write_text = query_info+'\\$\\$'+key_info+'\\n'\n",
    "        \n",
    "        a = write_text.strip().split('\\$\\$')\n",
    "        if len(a) == 2:\n",
    "            query_all, key_all = a\n",
    "        else:\n",
    "            print(a)\n",
    "            raise ValueError('stop')\n",
    "        query_and_neighbors = query_all.split('\\t')\n",
    "        key_and_neighbors = key_all.split('\\t')\n",
    "\n",
    "        if len(query_and_neighbors) != 1 + book_neighbour + shelves_neighbour + author_neighbour + 3:\n",
    "            query_cnt += 1\n",
    "            continue\n",
    "        if len(key_and_neighbors) != 1 + book_neighbour + shelves_neighbour + author_neighbour + 3:\n",
    "            key_cnt += 1\n",
    "            continue\n",
    "        \n",
    "        fout.write(write_text)\n",
    "        \n",
    "print(f'query_cnt:{query_cnt}, key_cnt:{key_cnt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4672d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation file generation\n",
    "\n",
    "blank_cnt = 0\n",
    "\n",
    "with open('data/book/val.tsv', 'w') as fout:\n",
    "    for b in tqdm(val_data):\n",
    "        query_info_dict = deepcopy(b)\n",
    "        if len(query_info_dict['similar_books']) == 0:\n",
    "            blank_cnt += 1\n",
    "            continue\n",
    "        \n",
    "        # sample key\n",
    "        random.shuffle(query_info_dict['similar_books'])\n",
    "        sample_key = query_info_dict['similar_books'].pop(0)\n",
    "        \n",
    "        key_info_dict = deepcopy(train_book_dict[sample_key])\n",
    "        \n",
    "        # sampling\n",
    "        query_info = mysampling(query_info_dict)\n",
    "        key_info = mysampling(key_info_dict)\n",
    "        \n",
    "        if query_info.split('\\t') != 1 + book_neighbour + shelves_neighbour + author_neighbour + 3:\n",
    "            continue\n",
    "        if key_info.split('\\t') != 1 + book_neighbour + shelves_neighbour + author_neighbour + 3:\n",
    "            continue\n",
    "        \n",
    "        fout.write(query_info+'\\$\\$'+key_info+'\\n')\n",
    "\n",
    "print(f'Blank:{blank_cnt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d733de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test file generation\n",
    "\n",
    "blank_cnt = 0\n",
    "\n",
    "with open('data/book/test.tsv', 'w') as fout:\n",
    "    for b in tqdm(test_data):\n",
    "        query_info_dict = deepcopy(b)\n",
    "        if len(query_info_dict['similar_books']) == 0:\n",
    "            blank_cnt += 1\n",
    "            continue\n",
    "        \n",
    "        # sample key\n",
    "        random.shuffle(query_info_dict['similar_books'])\n",
    "        sample_key = query_info_dict['similar_books'].pop(0)\n",
    "        \n",
    "        key_info_dict = deepcopy(train_book_dict[sample_key])\n",
    "        \n",
    "        # sampling\n",
    "        query_info = mysampling(query_info_dict)\n",
    "        key_info = mysampling(key_info_dict)\n",
    "        \n",
    "        if query_info.split('\\t') != 1 + book_neighbour + shelves_neighbour + author_neighbour + 3:\n",
    "            continue\n",
    "        if key_info.split('\\t') != 1 + book_neighbour + shelves_neighbour + author_neighbour + 3:\n",
    "            continue\n",
    "        \n",
    "        fout.write(query_info+'\\$\\$'+key_info+'\\n')\n",
    "        \n",
    "print(f'Blank:{blank_cnt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3e3b04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cdfb8d3",
   "metadata": {},
   "source": [
    "## generate pretrain raw file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5977944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate neighbour dict\n",
    "\n",
    "shelves_neighbour = {}\n",
    "author_neighbour = {}\n",
    "publisher_neighbour = {}\n",
    "language_code_neighbour = {}\n",
    "format_neighbour = {}\n",
    "\n",
    "for b in tqdm(train_data):\n",
    "    \n",
    "    # shelves\n",
    "    for ss in b['popular_shelves']:\n",
    "        if ss['name'] in shelves_id2idx_dict:\n",
    "            if ss['name'] not in shelves_neighbour:\n",
    "                shelves_neighbour[ss['name']] = []\n",
    "            shelves_neighbour[ss['name']].append(remove_next_line(b['title']+b['description']))\n",
    "    \n",
    "    # author\n",
    "    for aa in b['authors']:\n",
    "        if aa['author_id'] in author_id2idx_dict:\n",
    "            if aa['author_id'] not in author_neighbour:\n",
    "                author_neighbour[aa['author_id']] = []\n",
    "            author_neighbour[aa['author_id']].append(remove_next_line(b['title']+b['description']))\n",
    "    \n",
    "    # publisher\n",
    "    if b['publisher'] != '' and b['publisher'] in publisher_id2idx_dict:\n",
    "        if b['publisher'] not in publisher_neighbour:\n",
    "            publisher_neighbour[b['publisher']] = []\n",
    "        publisher_neighbour[b['publisher']].append(remove_next_line(b['title']+b['description']))\n",
    "    \n",
    "    # language_code\n",
    "    if b['language_code'] != '' and b['language_code'] in language_code_id2idx_dict:\n",
    "        if b['language_code'] not in language_code_neighbour:\n",
    "            language_code_neighbour[b['language_code']] = []\n",
    "        language_code_neighbour[b['language_code']].append(remove_next_line(b['title']+b['description']))\n",
    "    \n",
    "    # format\n",
    "    if b['format'] != '' and b['format'] in format_id2idx_dict:\n",
    "        if b['format'] not in format_neighbour:\n",
    "            format_neighbour[b['format']] = []\n",
    "        format_neighbour[b['format']].append(remove_next_line(b['title']+b['description']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e637d2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shelves_neighbour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb2dff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(author_neighbour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3799e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(publisher_neighbour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8027e590",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(language_code_neighbour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732a9288",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(format_neighbour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bfb2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save id2idx\n",
    "pickle.dump(shelves_id2idx_dict, open('data/book/neighbour/shelves_id2idx_dict.pkl', 'wb'))\n",
    "pickle.dump(author_id2idx_dict, open('data/book/neighbour/author_id2idx_dict.pkl', 'wb'))\n",
    "pickle.dump(publisher_id2idx_dict, open('data/book/neighbour/publisher_id2idx_dict.pkl', 'wb'))\n",
    "pickle.dump(language_code_id2idx_dict, open('data/book/neighbour/language_code_id2idx_dict.pkl', 'wb'))\n",
    "pickle.dump(format_id2idx_dict, open('data/book/neighbour/format_id2idx_dict.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8e3f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save neighbour dict\n",
    "pickle.dump(shelves_neighbour, open('data/book/neighbour/shelves_neighbour.pkl', 'wb'))\n",
    "pickle.dump(author_neighbour, open('data/book/neighbour/author_neighbour.pkl', 'wb'))\n",
    "pickle.dump(publisher_neighbour, open('data/book/neighbour/publisher_neighbour.pkl', 'wb'))\n",
    "pickle.dump(language_code_neighbour, open('data/book/neighbour/language_code_neighbour.pkl', 'wb'))\n",
    "pickle.dump(format_neighbour, open('data/book/neighbour/format_neighbour.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664fa46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save number statistics\n",
    "pickle.dump([6632, 205891, 62934, 139, 768], open('data/book/shelves_neighbour.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5316cb3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
