{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95dcef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49936ae",
   "metadata": {},
   "source": [
    "## read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e01b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "paper_dict: paper id -> title\n",
    "author_dict: author id (author num_id \\t author name) -> fos text\n",
    "paper_neighbour: key: paper id, value: dict['paper':(list), 'author':(list), 'venue':str]\n",
    "author_neighbour: key: author id (author num_id \\t author name), value: paper list\n",
    "venue_neighbour: key: venue name, value: paper list\n",
    "'''\n",
    "\n",
    "paper_dict = pickle.load(open('DBLP_neighbour/paper_dict.pkl','rb'))\n",
    "author_dict = pickle.load(open('DBLP_neighbour/author_dict.pkl','rb'))\n",
    "paper_neighbour = pickle.load(open('DBLP_neighbour/paper_neighbour_shuffle.pkl','rb'))\n",
    "author_neighbour = pickle.load(open('DBLP_neighbour/author_neighbour_shuffle.pkl','rb'))\n",
    "venue_neighbour = pickle.load(open('DBLP_neighbour/venue_neighbour_shuffle.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a0e8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'paper_dict.len:{len(paper_dict)}, author_dict.len:{len(author_dict)}')\n",
    "print(f'paper_neighbour.len:{len(paper_neighbour)},author_neighbour.len:{len(author_neighbour)},venue_neighbour.len:{len(venue_neighbour)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f94e95",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## paper_dict inverse\n",
    "paper_dict_inv = {paper_dict[p]:p for p in tqdm(paper_dict)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd74a984",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## author_dict inverse\n",
    "#author_dict_inv = {'[author]'+author_dict[a]:a for a in tqdm(author_dict)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb728fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c8bc748",
   "metadata": {},
   "source": [
    "## filter strange node (node with \\t \\n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8e60ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "You don't need to filter, since we have already filtered in sample_DBLP_homo_randomsplit.ipynb and save into xxx_neighbour_shuffle.pkl\n",
    "'''\n",
    "\n",
    "##paper_neighbour\n",
    "#paper_neighbour_filter = {}\n",
    "#filter_num = 0\n",
    "\n",
    "#for p in tqdm(paper_neighbour):\n",
    "#    paper_neighbour_filter[p] = {}\n",
    "#    \n",
    "#    # copy author and venue\n",
    "#    if 'author' in paper_neighbour[p]:\n",
    "#        paper_neighbour_filter[p]['author'] = paper_neighbour[p]['author']\n",
    "#    if 'venue' in paper_neighbour[p]:\n",
    "#        paper_neighbour_filter[p]['venue'] = paper_neighbour[p]['venue']\n",
    "#    \n",
    "#    if 'paper' in paper_neighbour[p]:\n",
    "#        tmp_paper = []\n",
    "#        for p_n in paper_neighbour[p]['paper']:\n",
    "#            if len(p_n.split('\\t')) == 1 and len(p_n.split('\\n')) == 1 and len(p_n.split('\\rm')) == 1 and len(p_n.split('\\r')) == 1 and len(p_n.split('$')) == 1:\n",
    "#                tmp_paper.append(p_n)\n",
    "#            else:\n",
    "#                filter_num += 1\n",
    "#        if len(tmp_paper) != 0:\n",
    "#            paper_neighbour_filter[p]['paper'] = tmp_paper\n",
    "#                \n",
    "#paper_neighbour = paper_neighbour_filter\n",
    "#print(f'filter_num:{filter_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bb75ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "##author_neighbour\n",
    "#author_neighbour_filter = {}\n",
    "#filter_num = 0\n",
    "#\n",
    "#for p in tqdm(author_neighbour):\n",
    "#    author_neighbour_filter[p] = []\n",
    "#    for p_n in author_neighbour[p]:\n",
    "#        if len(p_n.split('\\t')) == 1 and len(p_n.split('\\n')) == 1 and len(p_n.split('\\rm')) == 1 and len(p_n.split('\\r')) == 1 and len(p_n.split('$')) == 1:\n",
    "#            author_neighbour_filter[p].append(p_n)\n",
    "#        else:\n",
    "#            filter_num += 1\n",
    "#            \n",
    "#author_neighbour = author_neighbour_filter\n",
    "#print(f'filter_num:{filter_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5788a775",
   "metadata": {},
   "outputs": [],
   "source": [
    "##venue_neighbour\n",
    "#venue_neighbour_filter = {}\n",
    "#filter_num = 0\n",
    "\n",
    "#for p in tqdm(venue_neighbour):\n",
    "#    venue_neighbour_filter[p] = []\n",
    "#    for p_n in venue_neighbour[p]:\n",
    "#        if len(p_n.split('\\t')) == 1 and len(p_n.split('\\n')) == 1 and len(p_n.split('\\rm')) == 1 and len(p_n.split('\\r')) == 1 and len(p_n.split('$')) == 1:\n",
    "#            venue_neighbour_filter[p].append(p_n)\n",
    "#        else:\n",
    "#            filter_num += 1\n",
    "            \n",
    "#venue_neighbour = venue_neighbour_filter\n",
    "#print(f'filter_num:{filter_num}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7359bb6c",
   "metadata": {},
   "source": [
    "## random split into train/val/test (focus on paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e1afd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.7\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd98c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "You don't have to random split, just read the random split result from sample_DBLP_homo_randomsplit.ipynb is OK.\n",
    "'''\n",
    "train_id = pickle.load(open('DBLP_neighbour/random_train_id.pkl','rb'))\n",
    "val_id = pickle.load(open('DBLP_neighbour/random_val_id.pkl','rb'))\n",
    "test_id = pickle.load(open('DBLP_neighbour/random_test_id.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd2ddf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#paper_all = list(paper_neighbour.keys())\n",
    "#random.shuffle(paper_all)\n",
    "#\n",
    "#train_id = paper_all[:int(len(paper_all)*train_ratio)]\n",
    "#val_id = paper_all[int(len(paper_all)*train_ratio):int(len(paper_all)*(train_ratio+val_ratio))]\n",
    "#test_id = paper_all[int(len(paper_all)*(train_ratio+val_ratio)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd27be4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40f44843",
   "metadata": {},
   "source": [
    "## Shuffle neighbour dict once -> sample result will be same for each kind of generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c834b1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "paper_neighbour: key: paper id, value: dict['paper':(list), 'author':(list), 'venue':str]\n",
    "author_neighbour: key: author id (author num_id \\t author name), value: paper list\n",
    "venue_neighbour: key: venue name, value: paper list\n",
    "\n",
    "You don't need to shuffle here since xxx_neighbour_shuffle.pkl is read to make sure everything is aligned.\n",
    "\n",
    "'''\n",
    "# shuffle for paper_neighbour\n",
    "#for p in tqdm(paper_neighbour):\n",
    "#    if 'paper' in paper_neighbour[p]:\n",
    "#        random.shuffle(paper_neighbour[p]['paper'])\n",
    "#    if 'author' in paper_neighbour[p]:\n",
    "#        random.shuffle(paper_neighbour[p]['author'])\n",
    "#        \n",
    "# shuffle for author_neighbour\n",
    "#for a in tqdm(author_neighbour):\n",
    "#    random.shuffle(author_neighbour[a])\n",
    "\n",
    "# shuffle for venue_neighbour\n",
    "#for v in tqdm(venue_neighbour):\n",
    "#    random.shuffle(venue_neighbour[v])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed70326",
   "metadata": {},
   "source": [
    "## Some statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0dce63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# average neighbour papers/author for papers\n",
    "#author_cnt = 0\n",
    "#papers_cnt = 0\n",
    "#\n",
    "#for p in tqdm(paper_neighbour):\n",
    "#    if 'paper' in paper_neighbour[p]:\n",
    "#        papers_cnt += len(paper_neighbour[p]['paper'])\n",
    "#    if 'author' in paper_neighbour[p]:\n",
    "#        author_cnt += len(paper_neighbour[p]['author'])\n",
    "#        \n",
    "#print(f'Average Neighbour Paper:{papers_cnt/len(paper_neighbour)}, Average Neighbour Author:{author_cnt/len(paper_neighbour)} for each paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e60da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neighbour number based on the statistics above\n",
    "paper_neighbour_num = 5\n",
    "author_neighbour_num = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27e20f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97b1cd08",
   "metadata": {},
   "source": [
    "## Read train author & train venue and then reindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcbcaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train_author & index authors\n",
    "train_authors = pickle.load(open('DBLP_neighbour/random_train_authors.pkl','rb'))\n",
    "train_authors_id2idx = {}\n",
    "for a in train_authors:\n",
    "    train_authors_id2idx[a] = len(train_authors_id2idx)\n",
    "pickle.dump(train_authors_id2idx, open('DBLP_neighbour/random_train_authors_id2idx.pkl','wb'))\n",
    "print(f'Number of Author:{len(train_authors_id2idx)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17217fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_authors_idx2id = {train_authors_id2idx[idd]:idd for idd in tqdm(train_authors_id2idx)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0831821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train_venue & index venue\n",
    "train_venue = pickle.load(open('DBLP_neighbour/random_train_venue.pkl','rb'))\n",
    "train_venue_id2idx = {}\n",
    "for v in train_venue:\n",
    "    train_venue_id2idx[v] = len(train_venue_id2idx)\n",
    "pickle.dump(train_venue_id2idx, open('DBLP_neighbour/random_train_venue_id2idx.pkl','wb'))\n",
    "print(f'Number of Venue:{len(train_venue_id2idx)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b859cc",
   "metadata": {},
   "source": [
    "## Generate train_pp.tsv; val_pp.tsv; test_pp.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0bca54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_for_pp_train(file, input_id):\n",
    "    '''\n",
    "    Each line is in this format:\n",
    "    query_paper \\t q_n_paper1 \\t...\\t q_paperK \\t q_n_author1 \\t...\\t q_aM \\t q_venue \\$\\$ key_paper \\t k_n_paper1 \\t...\\t k_n_paperK \\t k_n_author1 \\t...\\t k_aM \\t k_venue \n",
    "    K = paper_neighbour_num\n",
    "    M = author_neighbour_num\n",
    "    '''\n",
    "    no_paper_neighbour = 0\n",
    "    key_no_neighbour = 0\n",
    "    false_text = 0\n",
    "    \n",
    "    with open(file,'w') as fout:\n",
    "        for idd in tqdm(input_id):\n",
    "            key_node = -1\n",
    "\n",
    "            ## if special character in paper_dict[idd](query), delete this sample\n",
    "            if len(paper_dict[idd].split('\\t')) != 1 or len(paper_dict[idd].split('\\n')) != 1 or len(paper_dict[idd].split('\\rm')) != 1 or len(paper_dict[idd].split('\\r')) != 1 or len(paper_dict[idd].split('$')) != 1:\n",
    "                continue\n",
    "\n",
    "            ## make sure that it has a paper neighbour\n",
    "            if 'paper' not in paper_neighbour[idd] or len(paper_neighbour[idd]['paper']) == 0:\n",
    "                no_paper_neighbour += 1\n",
    "                continue\n",
    "\n",
    "            # sample key node & neighbour\n",
    "            query_n_paper = paper_neighbour[idd]['paper']\n",
    "            if 'author' in paper_neighbour[idd]:\n",
    "                query_n_author = paper_neighbour[idd]['author'][:author_neighbour_num]\n",
    "                query_n_author = [str(train_authors_id2idx[a]) for a in query_n_author]\n",
    "            else:\n",
    "                query_n_author = ['-1'] * author_neighbour_num\n",
    "            if 'venue' in paper_neighbour[idd]:\n",
    "                query_venue = str(train_venue_id2idx[paper_neighbour[idd]['venue']])\n",
    "            else:\n",
    "                query_venue = '-1'\n",
    "            #random.shuffle(query_neighbour)\n",
    "\n",
    "            ## delete key_node\n",
    "            n = query_n_paper[0]\n",
    "            query_n_paper = query_n_paper[1:]\n",
    "            key_neighbour = paper_neighbour[paper_dict_inv[n]]\n",
    "            if 'paper' in key_neighbour:\n",
    "                key_n_paper = key_neighbour['paper']\n",
    "            else:\n",
    "                key_n_paper = [''] * paper_neighbour_num\n",
    "            if 'author' in key_neighbour:\n",
    "                key_n_author = key_neighbour['author'][:author_neighbour_num]\n",
    "                key_n_author = [str(train_authors_id2idx[a]) for a in key_n_author]\n",
    "            else:\n",
    "                key_n_author = ['-1'] * author_neighbour_num\n",
    "            if 'venue' in key_neighbour:\n",
    "                key_venue = str(train_venue_id2idx[key_neighbour['venue']])\n",
    "            else:\n",
    "                key_venue = '-1'\n",
    "            \n",
    "            ### if special character in paper_dict[idd](key), delete this sample\n",
    "            #if len(paper_dict[paper_dict_inv[n]].split('\\t')) != 1 or len(paper_dict[paper_dict_inv[n]].split('\\n')) != 1:\n",
    "            #    continue\n",
    "\n",
    "            ## sample neighbour for query\n",
    "            if len(query_n_paper) > paper_neighbour_num:\n",
    "                query_n_paper_text = '\\t'.join(query_n_paper[:paper_neighbour_num])\n",
    "            else:\n",
    "                query_n_paper_text = '\\t'.join(query_n_paper+[''] * (paper_neighbour_num - len(query_n_paper)))\n",
    "            if len(query_n_author) > author_neighbour_num:\n",
    "                query_n_author_text = '\\t'.join(query_n_author[:author_neighbour_num])\n",
    "            else:\n",
    "                query_n_author_text = '\\t'.join(query_n_author+['-1'] * (author_neighbour_num - len(query_n_author)))\n",
    "            \n",
    "            query_text = paper_dict[idd] + '\\t' + query_n_paper_text + '\\t' + query_n_author_text + '\\t' + query_venue\n",
    "\n",
    "            ## sample neighbour for key\n",
    "            if len(key_n_paper) > paper_neighbour_num:\n",
    "                key_n_paper_text = '\\t'.join(key_n_paper[:paper_neighbour_num])\n",
    "            else:\n",
    "                key_n_paper_text = '\\t'.join(key_n_paper+[''] * (paper_neighbour_num - len(key_n_paper)))\n",
    "            if len(key_n_author) > author_neighbour_num:\n",
    "                key_n_author_text = '\\t'.join(key_n_author[:author_neighbour_num])\n",
    "            else:\n",
    "                key_n_author_text = '\\t'.join(key_n_author+['-1'] * (author_neighbour_num - len(key_n_author)))\n",
    "            \n",
    "            key_text = paper_dict[paper_dict_inv[n]] + '\\t' + key_n_paper_text + '\\t' + key_n_author_text + '\\t' + key_venue\n",
    "\n",
    "            ## summary\n",
    "            write_down = query_text+'\\$\\$'+key_text+'\\n'\n",
    "            a = write_down.strip().split('\\$\\$')\n",
    "            if a[0] == query_text and a[1] == key_text:\n",
    "                if '\\n' not in query_text and '\\n' not in key_text:\n",
    "                    fout.write(write_down)\n",
    "                else:\n",
    "                    false_text += 1\n",
    "            else:\n",
    "                false_text += 1\n",
    "\n",
    "    print(f'Finish writing data into {file}')\n",
    "    print(f'No neighbour paper:{no_paper_neighbour}, all:{len(input_id)}')\n",
    "    print(f'false_text:{false_text}')\n",
    "    print('****************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f482ba85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_for_pp_eval(file, input_id, train_authors, train_venue):\n",
    "    '''\n",
    "    Each line is in this format:\n",
    "    query_paper \\t q_n_paper1 \\t...\\t q_paperK \\t q_n_author1 \\t...\\t q_aM \\t q_venue \\$\\$ key_paper \\t k_n_paper1 \\t...\\t k_n_paperK \\t k_n_author1 \\t...\\t k_aM \\t k_venue \n",
    "    K = paper_neighbour_num\n",
    "    M = author_neighbour_num\n",
    "    '''\n",
    "    no_paper_neighbour = 0\n",
    "    key_no_neighbour = 0\n",
    "    false_text = 0\n",
    "    \n",
    "    train_authors = set(train_authors)\n",
    "    train_venue = set(train_venue)\n",
    "    \n",
    "    with open(file,'w') as fout:\n",
    "        for idd in tqdm(input_id):\n",
    "            key_node = -1\n",
    "\n",
    "            ## if special character in paper_dict[idd](query), delete this sample\n",
    "            if len(paper_dict[idd].split('\\t')) != 1 or len(paper_dict[idd].split('\\n')) != 1 or len(paper_dict[idd].split('\\rm')) != 1 or len(paper_dict[idd].split('\\r')) != 1 or len(paper_dict[idd].split('$')) != 1:\n",
    "                continue\n",
    "\n",
    "            ## make sure that it has a paper neighbour\n",
    "            if 'paper' not in paper_neighbour[idd] or len(paper_neighbour[idd]['paper']) == 0:\n",
    "                no_paper_neighbour += 1\n",
    "                continue\n",
    "\n",
    "            # sample key node & neighbour\n",
    "            query_n_paper = paper_neighbour[idd]['paper']\n",
    "            if 'author' in paper_neighbour[idd]:\n",
    "                query_n_author = list(set(paper_neighbour[idd]['author']) & train_authors)\n",
    "                query_n_author = [str(train_authors_id2idx[a]) for a in query_n_author]\n",
    "            else:\n",
    "                query_n_author = ['-1'] * author_neighbour_num\n",
    "            if 'venue' in paper_neighbour[idd] and paper_neighbour[idd]['venue'] in train_venue:\n",
    "                query_venue = str(train_venue_id2idx[paper_neighbour[idd]['venue']])\n",
    "            else:\n",
    "                query_venue = '-1'\n",
    "            #random.shuffle(query_neighbour)\n",
    "\n",
    "            ## delete key_node\n",
    "            n = query_n_paper[0]\n",
    "            query_n_paper = query_n_paper[1:]\n",
    "            key_neighbour = paper_neighbour[paper_dict_inv[n]]\n",
    "            if 'paper' in key_neighbour:\n",
    "                key_n_paper = key_neighbour['paper']\n",
    "            else:\n",
    "                key_n_paper = [''] * paper_neighbour_num\n",
    "            if 'author' in key_neighbour:\n",
    "                key_n_author = list(set(key_neighbour['author']) & train_authors)\n",
    "                key_n_author = [str(train_authors_id2idx[a]) for a in key_n_author]\n",
    "            else:\n",
    "                key_n_author = ['-1'] * author_neighbour_num\n",
    "            if 'venue' in key_neighbour and key_neighbour['venue'] in train_venue:\n",
    "                key_venue = str(train_venue_id2idx[key_neighbour['venue']])\n",
    "            else:\n",
    "                key_venue = '-1'\n",
    "            \n",
    "            ### if special character in paper_dict[idd](key), delete this sample\n",
    "            #if len(paper_dict[paper_dict_inv[n]].split('\\t')) != 1 or len(paper_dict[paper_dict_inv[n]].split('\\n')) != 1:\n",
    "            #    continue\n",
    "\n",
    "            ## sample neighbour for query\n",
    "            if len(query_n_paper) > paper_neighbour_num:\n",
    "                query_n_paper_text = '\\t'.join(query_n_paper[:paper_neighbour_num])\n",
    "            else:\n",
    "                query_n_paper_text = '\\t'.join(query_n_paper+[''] * (paper_neighbour_num - len(query_n_paper)))\n",
    "            if len(query_n_author) > author_neighbour_num:\n",
    "                query_n_author_text = '\\t'.join(query_n_author[:author_neighbour_num])\n",
    "            else:\n",
    "                query_n_author_text = '\\t'.join(query_n_author+['-1'] * (author_neighbour_num - len(query_n_author)))\n",
    "            \n",
    "            query_text = paper_dict[idd] + '\\t' + query_n_paper_text + '\\t' + query_n_author_text + '\\t' + query_venue\n",
    "\n",
    "            ## sample neighbour for key\n",
    "            if len(key_n_paper) > paper_neighbour_num:\n",
    "                key_n_paper_text = '\\t'.join(key_n_paper[:paper_neighbour_num])\n",
    "            else:\n",
    "                key_n_paper_text = '\\t'.join(key_n_paper+[''] * (paper_neighbour_num - len(key_n_paper)))\n",
    "            if len(key_n_author) > author_neighbour_num:\n",
    "                key_n_author_text = '\\t'.join(key_n_author[:author_neighbour_num])\n",
    "            else:\n",
    "                key_n_author_text = '\\t'.join(key_n_author+['-1'] * (author_neighbour_num - len(key_n_author)))\n",
    "            \n",
    "            key_text = paper_dict[paper_dict_inv[n]] + '\\t' + key_n_paper_text + '\\t' + key_n_author_text + '\\t' + key_venue\n",
    "\n",
    "            ## summary\n",
    "            write_down = query_text+'\\$\\$'+key_text+'\\n'\n",
    "            a = write_down.strip().split('\\$\\$')\n",
    "            if a[0] == query_text and a[1] == key_text:\n",
    "                if '\\n' not in query_text and '\\n' not in key_text:\n",
    "                    fout.write(write_down)\n",
    "                else:\n",
    "                    false_text += 1\n",
    "            else:\n",
    "                false_text += 1\n",
    "\n",
    "    print(f'Finish writing data into {file}')\n",
    "    print(f'No neighbour paper:{no_paper_neighbour}, all:{len(input_id)}')\n",
    "    print(f'false_text:{false_text}')\n",
    "    print('****************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c6da3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_for_pp_train(file='DBLP_heter/train_pp.tsv', input_id=train_id)\n",
    "write_for_pp_eval(file='DBLP_heter/val_pp.tsv', input_id=val_id, train_authors=train_authors, train_venue=train_venue)\n",
    "write_for_pp_eval(file='DBLP_heter/test_pp.tsv', input_id=test_id, train_authors=train_authors, train_venue=train_venue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6a080e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdd320e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c89af70",
   "metadata": {},
   "source": [
    "## Generate train_pa.tsv; (val_pa.tsv; test_pa.tsv are tricky)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60a9326",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## regenerate author_neighbour depending on train_id\n",
    "author_neighbour_train = defaultdict(list)\n",
    "\n",
    "val_id_set = set(val_id)\n",
    "test_id_set = set(test_id)\n",
    "\n",
    "for a in tqdm(author_neighbour):\n",
    "    for p in author_neighbour[a]:\n",
    "        if len(set(paper_dict_inv[p]) & val_id_set) == 0 and len(set(paper_dict_inv[p]) & test_id_set) == 0:\n",
    "            author_neighbour_train[a].append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea76ecd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_for_pa_train(file, input_id):\n",
    "    '''\n",
    "    Each line is in this format:\n",
    "    query_paper \\t q_n_paper1 \\t...\\t q_paperK \\t q_n_author1 \\t...\\t q_aM \\t q_venue \\$\\$ key_author \\t k_n_paper1 \\t...\\t k_n_paperK \n",
    "    K = paper_neighbour_num\n",
    "    M = author_neighbour_num\n",
    "    '''\n",
    "    no_author_neighbour = 0\n",
    "    key_no_neighbour = 0\n",
    "    false_text = 0\n",
    "    \n",
    "    random.seed(42)\n",
    "    \n",
    "    with open(file,'w') as fout:\n",
    "        for idd in tqdm(input_id):\n",
    "            key_node = -1\n",
    "\n",
    "            ## if special character in paper_dict[idd](query), delete this sample\n",
    "            if len(paper_dict[idd].split('\\t')) != 1 or len(paper_dict[idd].split('\\n')) != 1 or len(paper_dict[idd].split('\\rm')) != 1 or len(paper_dict[idd].split('\\r')) != 1 or len(paper_dict[idd].split('$')) != 1:\n",
    "                continue\n",
    "\n",
    "            ## make sure that it has an author neighbour\n",
    "            if 'author' not in paper_neighbour[idd] or len(paper_neighbour[idd]['author']) == 0:\n",
    "                no_author_neighbour += 1\n",
    "                continue\n",
    "                \n",
    "            # sample key node & neighbour\n",
    "            query_n_author = paper_neighbour[idd]['author']\n",
    "            if 'paper' in paper_neighbour[idd]:\n",
    "                query_n_paper = paper_neighbour[idd]['paper'][:paper_neighbour_num]\n",
    "                #query_n_paper = [str(train_authors_id2idx[a]) for a in query_n_author]\n",
    "            else:\n",
    "                query_n_paper = [''] * paper_neighbour_num\n",
    "            if 'venue' in paper_neighbour[idd] and paper_neighbour[idd]['venue'] in train_venue_id2idx:\n",
    "                query_venue = str(train_venue_id2idx[paper_neighbour[idd]['venue']])\n",
    "            else:\n",
    "                query_venue = '-1'            \n",
    "            \n",
    "            ## delete key_node\n",
    "            #n = query_n_author[0]\n",
    "            #query_n_author = query_n_author[1:]\n",
    "            query_n_author = [str(train_authors_id2idx[a]) for a in query_n_author if a in train_authors_id2idx]\n",
    "            if len(query_n_author) == 0:\n",
    "                no_author_neighbour += 1\n",
    "                continue\n",
    "            n = train_authors_idx2id[int(query_n_author[0])]\n",
    "            query_n_author = query_n_author[1:]\n",
    "            key_n_paper = author_neighbour_train[n]\n",
    "            random.shuffle(key_n_paper)\n",
    "            \n",
    "            ### if special character in paper_dict[idd](key), delete this sample\n",
    "            #if len(paper_dict[paper_dict_inv[n]].split('\\t')) != 1 or len(paper_dict[paper_dict_inv[n]].split('\\n')) != 1:\n",
    "            #    continue\n",
    "\n",
    "            ## sample neighbour for query\n",
    "            if len(query_n_paper) > paper_neighbour_num:\n",
    "                query_n_paper_text = '\\t'.join(query_n_paper[:paper_neighbour_num])\n",
    "            else:\n",
    "                query_n_paper_text = '\\t'.join(query_n_paper+[''] * (paper_neighbour_num - len(query_n_paper)))\n",
    "            if len(query_n_author) > author_neighbour_num:\n",
    "                query_n_author_text = '\\t'.join(query_n_author[:author_neighbour_num])\n",
    "            else:\n",
    "                query_n_author_text = '\\t'.join(query_n_author+['-1'] * (author_neighbour_num - len(query_n_author)))\n",
    "            \n",
    "            query_text = paper_dict[idd] + '\\t' + query_n_paper_text + '\\t' + query_n_author_text + '\\t' + query_venue\n",
    "\n",
    "            ## sample neighbour for key\n",
    "            if len(key_n_paper) > paper_neighbour_num:\n",
    "                key_n_paper_text = '\\t'.join(key_n_paper[:paper_neighbour_num])\n",
    "            else:\n",
    "                key_n_paper_text = '\\t'.join(key_n_paper+[''] * (paper_neighbour_num - len(key_n_paper)))\n",
    "            \n",
    "            key_text = str(train_authors_id2idx[n]) + '\\t' + key_n_paper_text\n",
    "\n",
    "            ## summary\n",
    "            write_down = query_text+'\\$\\$'+key_text+'\\n'\n",
    "            a = write_down.strip().split('\\$\\$')\n",
    "            if a[0] == query_text and a[1] == key_text:\n",
    "                if '\\n' not in query_text and '\\n' not in key_text:\n",
    "                    fout.write(write_down)\n",
    "                else:\n",
    "                    false_text += 1\n",
    "            else:\n",
    "                false_text += 1\n",
    "\n",
    "    print(f'Finish writing data into {file}')\n",
    "    print(f'No neighbour paper:{no_author_neighbour}, all:{len(input_id)}')\n",
    "    print(f'false_text:{false_text}')\n",
    "    print('****************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5be9ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_for_pa_train(file='DBLP_heter/train_pa.tsv', input_id=train_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d46f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510806d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47aa94c1",
   "metadata": {},
   "source": [
    "## Generate train_pv.tsv; (val_pv.tsv; test_pv.tsv are tricky)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe3ee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## regenerate venue_neighbour depending on train_id\n",
    "venue_neighbour_train = defaultdict(list)\n",
    "\n",
    "val_id_set = set(val_id)\n",
    "test_id_set = set(test_id)\n",
    "\n",
    "for v in tqdm(venue_neighbour):\n",
    "    for p in venue_neighbour[v]:\n",
    "        if len(set(paper_dict_inv[p]) & val_id_set) == 0 and len(set(paper_dict_inv[p]) & test_id_set) == 0:\n",
    "            venue_neighbour_train[v].append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c1184f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_for_pv_train(file, input_id):\n",
    "    '''\n",
    "    Each line is in this format:\n",
    "    query_paper \\t q_n_paper1 \\t...\\t q_paperK \\t q_n_author1 \\t...\\t q_aM \\$\\$ key_venue \\t k_n_paper1 \\t...\\t k_n_paperK \n",
    "    K = paper_neighbour_num\n",
    "    M = author_neighbour_num\n",
    "    '''\n",
    "    no_venue_neighbour = 0\n",
    "    key_no_neighbour = 0\n",
    "    false_text = 0\n",
    "    \n",
    "    random.seed(42)\n",
    "    \n",
    "    with open(file,'w') as fout:\n",
    "        for idd in tqdm(input_id):\n",
    "            key_node = -1\n",
    "\n",
    "            ## if special character in paper_dict[idd](query), delete this sample\n",
    "            if len(paper_dict[idd].split('\\t')) != 1 or len(paper_dict[idd].split('\\n')) != 1 or len(paper_dict[idd].split('\\rm')) != 1 or len(paper_dict[idd].split('\\r')) != 1 or len(paper_dict[idd].split('$')) != 1:\n",
    "                continue\n",
    "\n",
    "            ## make sure that it has an author neighbour\n",
    "            if 'venue' not in paper_neighbour[idd] or paper_neighbour[idd]['venue'] not in train_venue_id2idx:\n",
    "                no_venue_neighbour += 1\n",
    "                continue                \n",
    "\n",
    "            # sample key node & neighbour\n",
    "            query_n_author = paper_neighbour[idd]['author']\n",
    "            if 'paper' in paper_neighbour[idd]:\n",
    "                query_n_paper = paper_neighbour[idd]['paper'][:paper_neighbour_num]\n",
    "            else:\n",
    "                query_n_paper = [''] * paper_neighbour_num\n",
    "            if 'author' in paper_neighbour[idd]:\n",
    "                query_n_author = paper_neighbour[idd]['author']\n",
    "                query_n_author = [str(train_authors_id2idx[a]) for a in query_n_author if a in train_authors_id2idx]\n",
    "            else:\n",
    "                query_n_paper = ['-1'] * author_neighbour_num\n",
    "            query_venue = paper_neighbour[idd]['venue']          \n",
    "            \n",
    "            ## delete key_node\n",
    "            if len(venue_neighbour_train[query_venue]) > paper_neighbour_num:\n",
    "                key_n_paper = []\n",
    "                for i in np.random.randint(len(venue_neighbour_train[query_venue]),size=paper_neighbour_num):\n",
    "                    key_n_paper.append(venue_neighbour_train[query_venue][i])\n",
    "            else:\n",
    "                key_n_paper = venue_neighbour_train[query_venue]\n",
    "            \n",
    "            #random.shuffle(key_n_paper)\n",
    "            \n",
    "            ### if special character in paper_dict[idd](key), delete this sample\n",
    "            #if len(paper_dict[paper_dict_inv[n]].split('\\t')) != 1 or len(paper_dict[paper_dict_inv[n]].split('\\n')) != 1:\n",
    "            #    continue\n",
    "\n",
    "            ## sample neighbour for query\n",
    "            if len(query_n_paper) > paper_neighbour_num:\n",
    "                query_n_paper_text = '\\t'.join(query_n_paper[:paper_neighbour_num])\n",
    "            else:\n",
    "                query_n_paper_text = '\\t'.join(query_n_paper+[''] * (paper_neighbour_num - len(query_n_paper)))\n",
    "            if len(query_n_author) > author_neighbour_num:\n",
    "                query_n_author_text = '\\t'.join(query_n_author[:author_neighbour_num])\n",
    "            else:\n",
    "                query_n_author_text = '\\t'.join(query_n_author+['-1'] * (author_neighbour_num - len(query_n_author)))\n",
    "            \n",
    "            query_text = paper_dict[idd] + '\\t' + query_n_paper_text + '\\t' + query_n_author_text\n",
    "\n",
    "            ## sample neighbour for key\n",
    "            if len(key_n_paper) > paper_neighbour_num:\n",
    "                key_n_paper_text = '\\t'.join(key_n_paper[:paper_neighbour_num])\n",
    "            else:\n",
    "                key_n_paper_text = '\\t'.join(key_n_paper+[''] * (paper_neighbour_num - len(key_n_paper)))\n",
    "            \n",
    "            key_text = str(train_venue_id2idx[query_venue]) + '\\t' + key_n_paper_text\n",
    "            \n",
    "            ## summary\n",
    "            write_down = query_text+'\\$\\$'+key_text+'\\n'\n",
    "            a = write_down.strip().split('\\$\\$')\n",
    "            if a[0] == query_text and a[1] == key_text:\n",
    "                if '\\n' not in query_text and '\\n' not in key_text:\n",
    "                    fout.write(write_down)\n",
    "                else:\n",
    "                    false_text += 1\n",
    "            else:\n",
    "                false_text += 1\n",
    "\n",
    "    print(f'Finish writing data into {file}')\n",
    "    print(f'No neighbour paper:{no_venue_neighbour}, all:{len(input_id)}')\n",
    "    print(f'false_text:{false_text}')\n",
    "    print('****************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993e5de8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "write_for_pv_train(file='DBLP_heter/train_pv.tsv', input_id=train_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13808e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35e42ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7dc0f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
