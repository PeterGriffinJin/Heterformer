{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e43c1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17eaedbb",
   "metadata": {},
   "source": [
    "## merge NY & LA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a311d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge\n",
    "with open('raw/tweets-la.json') as f:\n",
    "    readin1 = f.readlines()\n",
    "    \n",
    "with open('raw/tweets-ny.json') as f:\n",
    "    readin2 = f.readlines()\n",
    "    \n",
    "readin = readin1 + readin2\n",
    "print(len(readin1))\n",
    "print(len(readin2))\n",
    "print(len(readin))\n",
    "\n",
    "print(readin[0])\n",
    "random.shuffle(readin)\n",
    "print(readin[1])\n",
    "\n",
    "print(len(readin))\n",
    "\n",
    "with open('tweets.json','w') as fout:\n",
    "    for line in readin:\n",
    "        fout.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5251a5",
   "metadata": {},
   "source": [
    "## data statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281de0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "with open('tweets.json') as f:\n",
    "    readin = f.readlines()\n",
    "    for line in tqdm(readin):\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fb0176",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfd2116",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text_dict = {} # key:tweet_id, value: tweet_text\n",
    "tweet_author_dict = {} # key:tweet_id, value: author_id\n",
    "tweet_poi_dict = {} # key:tweet_id, value: poi_id\n",
    "tweet_tags = {} # key:tweet_id, value: tag list\n",
    "tweet_mentions = {} # key:tweet_id, value: mentions list\n",
    "\n",
    "poi_text_dict = {} # key:poi_id, value: text\n",
    "poi_label_dict = {} # key:poi_id, value: poi_label\n",
    "poi_tweet_dict = defaultdict(list) # key:poi_id, value: tweet_id list\n",
    "\n",
    "author_tweet_dict = defaultdict(list) #key: author_id, value: tweet_id list\n",
    "tag_tweet_dict = defaultdict(list) #key: tag_name, value: tweet_id list\n",
    "mention_tweet_dict = defaultdict(list) #key: mention_name, value: tweet_id list\n",
    "\n",
    "label_poi_dict = defaultdict(list) #key: label_name, value: poi_id list\n",
    "\n",
    "for d in tqdm(data):\n",
    "    tweet_text_dict[d['tweet_id']] = d['tweet_text']\n",
    "    tweet_author_dict[d['tweet_id']] = d['author_id']\n",
    "    tweet_poi_dict[d['tweet_id']] = d['poi_id']\n",
    "    tweet_tags[d['tweet_id']] = d['tags']\n",
    "    tweet_mentions[d['tweet_id']] = d['mentions']\n",
    "    \n",
    "    for t in d['tags']:\n",
    "        tag_tweet_dict[t].append(d['tweet_id'])\n",
    "    for m in d['mentions']:\n",
    "        mention_tweet_dict[m].append(d['tweet_id'])\n",
    "    label_poi_dict[d['label']].append(d['poi_id'])\n",
    "    \n",
    "    poi_text_dict[d['poi_id']] = d['poi_text']\n",
    "    poi_label_dict[d['poi_id']] = d['label']\n",
    "    poi_tweet_dict[d['poi_id']].append(d['tweet_id'])\n",
    "    \n",
    "    author_tweet_dict[d['author_id']].append(d['tweet_id'])\n",
    "\n",
    "print(f'Number of tweet:{len(tweet_text_dict)}, Number of POI:{len(poi_text_dict)}, Number of labels:{len(label_poi_dict)}')\n",
    "print(f'Number of tags:{len(tag_tweet_dict)}, Number of mentions:{len(mention_tweet_dict)}, Number of authors:{len(author_tweet_dict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27306ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics on tags\n",
    "summ = 0\n",
    "thresh = 3\n",
    "cnt = 0\n",
    "\n",
    "for t in tag_tweet_dict:\n",
    "    summ += len(tag_tweet_dict[t])\n",
    "    if len(tag_tweet_dict[t]) >= thresh:\n",
    "        cnt += 1\n",
    "    #print(len(tag_tweet_dict[t]))\n",
    "print(f'Average:{summ/len(tag_tweet_dict)}, Cnt:{cnt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9831e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics on mentions\n",
    "summ = 0\n",
    "thresh = 3\n",
    "cnt = 0\n",
    "\n",
    "for t in mention_tweet_dict:\n",
    "    summ += len(mention_tweet_dict[t])\n",
    "    if len(mention_tweet_dict[t]) >= thresh:\n",
    "        cnt += 1\n",
    "    #print(len(mention_tweet_dict[t]))\n",
    "print(f'Average:{summ/len(mention_tweet_dict)}, Cnt:{cnt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c43d4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics on authors\n",
    "summ = 0\n",
    "thresh = 3\n",
    "cnt = 0\n",
    "\n",
    "for t in author_tweet_dict:\n",
    "    summ += len(author_tweet_dict[t])\n",
    "    if len(author_tweet_dict[t]) >= thresh:\n",
    "        cnt += 1\n",
    "    #print(len(author_tweet_dict[t]))\n",
    "print(f'Average:{summ/len(author_tweet_dict)}, Cnt:{cnt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd26096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics on O\n",
    "summ = 0\n",
    "thresh = 2\n",
    "cnt = 0\n",
    "\n",
    "for t in poi_tweet_dict:\n",
    "    summ += len(poi_tweet_dict[t])\n",
    "    if len(poi_tweet_dict[t]) >= thresh:\n",
    "        cnt += 1\n",
    "    #print(len(poi_tweet_dict[t]))\n",
    "print(f'Average:{summ/len(poi_tweet_dict)}, Cnt:{cnt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74268358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbbf074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter text length\n",
    "summ = 0\n",
    "for t in tweet_text_dict:\n",
    "    summ += len(tweet_text_dict[t].split())\n",
    "print(summ/len(tweet_text_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d23d330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poi text length\n",
    "summ = 0\n",
    "for t in poi_text_dict:\n",
    "    summ += len(poi_text_dict[t].split())\n",
    "print(summ/len(poi_text_dict))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f13e0cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1342fe23",
   "metadata": {},
   "source": [
    "## Seperate train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e240e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tweets.json') as f:\n",
    "    readin = f.readlines()\n",
    "print(len(readin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ebc1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate data\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.1\n",
    "\n",
    "train_set = readin[:int(len(readin)* train_ratio)]\n",
    "val_set = readin[int(len(readin)* train_ratio):int(len(readin)* (train_ratio+val_ratio))]\n",
    "test_set = readin[int(len(readin)* (train_ratio+val_ratio)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ee65d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file\n",
    "with open('raw/train.tsv','w') as fout:\n",
    "    for line in train_set:\n",
    "        fout.write(line)\n",
    "\n",
    "with open('raw/val.tsv','w') as fout:\n",
    "    for line in val_set:\n",
    "        fout.write(line)\n",
    "        \n",
    "with open('raw/test.tsv','w') as fout:\n",
    "    for line in test_set:\n",
    "        fout.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45418ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5881d09b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
